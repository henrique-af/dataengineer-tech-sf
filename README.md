## **Data Engineer - Teste Técnico**

Este repositório contém uma simulação de um pipeline de dados utilizando Google Cloud Platform (GCP) e Apache Airflow, conforme solicitado no teste técnico. O objetivo é demonstrar o conhecimento na construção de pipelines de dados que integram múltiplas etapas, desde a extração até a entrega dos dados processados.

### **Arquitetura Implementada**

A arquitetura proposta inclui as seguintes tecnologias e componentes:

- **Google Cloud Storage (GCS):** Usado como repositório de arquivos para armazenar dados brutos e processados.
- **Google Cloud Composer (Airflow):** Utilizado para orquestrar o pipeline de dados em batch.
- **Arquivos ZIP:** Arquivos de teste utilizados como input para o pipeline, simulando dados que chegam na Landing Zone.